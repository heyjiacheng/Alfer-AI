# Backend_Red_Panda 项目功能说明文档

## 项目概述

Backend_Red_Panda 是一个基于知识库的文档管理和查询系统，它允许用户上传、管理文档，并对这些文档进行语义化查询。该系统利用向量数据库和大语言模型实现了对文档的智能理解和响应能力。

## 系统架构

该项目主要由以下几个部分组成：

1. **Web API 服务**：基于 Flask 框架的 RESTful API
2. **文档处理系统**：负责文档上传、文本提取和嵌入
3. **向量数据库**：存储文档的语义向量表示
4. **查询处理系统**：处理用户查询，检索相关文档片段，使用 LLM 生成回答
5. **会话管理系统**：存储和管理用户与系统的对话历史

## 核心功能模块

### 1. 知识库管理

知识库（Knowledge Base）是文档的逻辑集合，系统支持创建多个知识库，每个知识库可以包含多个文档。

#### 主要功能：
- 创建新的知识库
- 获取知识库列表
- 查看特定知识库详情
- 更新知识库信息
- 删除知识库

### 2. 文档管理

系统支持上传、下载和管理各种类型的文档（主要是 PDF 文件）。

#### 主要功能：
- 上传文档到指定的知识库
- 获取所有文档列表
- 查看特定文档的详情
- 下载文档
- 删除文档

#### 文档处理流程：
1. 上传文件到临时目录
2. 进行文本提取（支持多种方法，包括 OCR）
3. 文本分块处理
4. 生成文本嵌入向量
5. 存储到向量数据库
6. 保存文档元数据到 SQLite 数据库

### 3. 向量嵌入系统

该系统负责将文档转换为向量表示，以支持语义检索。

#### 主要功能：
- 文档文本提取
- 文本分块
- 向量嵌入生成
- 向量存储

#### 技术亮点：
- 支持多种文本提取方法
- 针对扫描PDF使用OCR处理
- 智能文本分块算法
- 使用高质量的文本嵌入模型

### 4. 查询处理系统

该系统处理用户查询，检索相关文档，并使用大语言模型生成回答。

#### 主要功能：
- 接收用户查询
- 查询向量化
- 多知识库检索
- 相关文档片段检索
- 回答生成
- 源文档追溯

#### 技术亮点：
- 多查询生成技术（生成多个查询变体提高召回率）
- 文档相关性评分
- 对检索到的文档进行重排序
- 生成包含源文档引用的回答

### 5. 会话管理系统

该系统管理用户与系统的对话历史。

#### 主要功能：
- 创建新会话
- 获取会话列表
- 查看特定会话详情
- 删除会话
- 向会话添加消息

## 技术实现

### 数据库结构

系统使用 SQLite 数据库存储元数据：

#### 主要表：
1. **knowledge_bases**：存储知识库信息
   - id, name, description, created_at

2. **documents**：存储文档元数据
   - id, original_filename, stored_filename, upload_date, file_path, file_size, metadata, knowledge_base_id, extraction_failed

3. **conversations**：存储会话信息
   - id, title, created_at, knowledge_base_id

4. **conversation_messages**：存储会话消息
   - id, conversation_id, message_type, content, timestamp, sources

### 使用的核心技术

1. **框架和库**：
   - Flask：Web API 框架
   - Langchain：LLM 应用框架
   - Ollama：本地部署的 LLM 服务

2. **模型**：
   - 文本生成：deepseek-r1:1.5b (默认，可在环境变量中配置)
   - 文本嵌入：nomic-embed-text

3. **文档处理**：
   - 多种文本提取器：PyPDFLoader, UnstructuredPDFLoader
   - 文本分块：RecursiveCharacterTextSplitter
   - OCR 处理：pdf2image

4. **向量存储**：
   - Chroma 向量数据库

## API 端点

### 知识库管理
- `GET /knowledge-bases` - 获取所有知识库
- `POST /knowledge-bases` - 创建新知识库
- `GET /knowledge-bases/<kb_id>` - 获取特定知识库详情
- `PUT /knowledge-bases/<kb_id>` - 更新知识库信息
- `DELETE /knowledge-bases/<kb_id>` - 删除知识库

### 文档管理
- `GET /documents` - 获取所有文档
- `GET /documents?knowledge_base_id=<kb_id>` - 获取特定知识库的文档
- `GET /documents/<doc_id>` - 获取特定文档详情
- `GET /documents/<doc_id>/download` - 下载文档
- `DELETE /documents/<doc_id>` - 删除文档
- `POST /upload/<kb_id>` - 上传文档到指定知识库

### 查询功能
- `POST /query` - 处理查询请求

### 会话管理
- `GET /conversations` - 获取所有会话
- `GET /conversations?knowledge_base_id=<kb_id>` - 获取特定知识库的会话
- `POST /conversations` - 创建新会话
- `GET /conversations/<conv_id>` - 获取特定会话详情
- `DELETE /conversations/<conv_id>` - 删除会话
- `POST /conversations/<conv_id>/messages` - 向会话添加消息

## 部署与配置

### 环境设置
1. 安装 Ollama 并下载所需模型：
```bash
# 下载语言模型
ollama run deepseek-r1:1.5b
# 下载文本嵌入模型
ollama pull nomic-embed-text
```

2. 安装依赖：
```bash
pip install -r requirements.txt
```

3. 启动后端服务：
```bash
python3 app.py
```

### 配置选项
系统通过环境变量提供配置选项，可以在 `.env` 文件中设置：
- `TEMP_FOLDER`：临时文件夹路径
- `DOCS_STORAGE`：文档存储路径
- `DB_PATH`：数据库文件路径
- `LLM_MODEL`：使用的语言模型名称

## 使用流程示例

### 基本使用流程
1. 创建知识库
2. 上传文档到知识库
3. 创建新会话
4. 发送查询，获取回答

### 查询示例
查询时必须指定要查询的知识库 ID，可以指定单个或多个知识库：
```json
{
  "query": "文档中的主要技术是什么？",
  "knowledge_base_ids": [1, 2],
  "conversation_id": 1
}
```

## 系统特点

1. **模块化设计**：各功能模块相互独立，易于扩展
2. **多知识库支持**：允许创建和管理多个知识库
3. **智能文档处理**：支持多种文本提取方法，包括OCR
4. **高质量检索**：使用语义向量检索和重排序
5. **会话管理**：支持保存和管理对话历史
6. **本地部署**：使用Ollama实现本地部署，保护数据安全

## 技术挑战与解决方案

1. **文档处理挑战**：
   - 挑战：不同类型PDF文档的文本提取
   - 解决方案：多种提取器结合，失败时使用OCR

2. **查询精确度**：
   - 挑战：提高检索相关性
   - 解决方案：多查询技术和重排序算法

3. **知识库管理**：
   - 挑战：有效组织大量文档
   - 解决方案：知识库概念和元数据管理

## 后续改进方向

1. 支持更多文档格式（如Word, PPT等）
2. 添加用户认证和权限管理
3. 改进文档处理速度和质量
4. 优化向量检索算法
5. 添加更多高级查询功能
6. 支持更多语言和定制化模型配置 